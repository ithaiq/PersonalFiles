#### IO复用模型对比、

三种模型本质都是同步IO，因为他们都需要在读写事件就绪后，自己进行读写，也就是说这个读写过程是阻塞的。

##### select

- 使用copy_from_user从用户空间拷贝fd_set到内核空间
- 注册回调函数__pollwait
- 遍历所有fd，调用其对应的poll方法（对于socket，这个poll方法是sock_poll，sock_poll根据情况会调用到tcp_poll,udp_poll或者datagram_poll）
- 以tcp_poll为例，其核心实现就是__pollwait，也就是上面注册的回调函数。
- __pollwait的主要工作就是把current（当前进程）挂到设备的等待队列中，不同的设备有不同的等待队列，对于tcp_poll来说，其等待队列是sk->sk_sleep（注意把进程挂到等待队列中并不代表进程已经睡眠了）。在设备收到一条消息（网络设备）或填写完文件数据（磁盘设备）后，会唤醒设备等待队列上睡眠的进程，这时current便被唤醒了。
- poll方法返回时会返回一个描述读写操作是否就绪的mask掩码，根据这个mask掩码给fd_set赋值。
- 如果遍历完所有的fd，还没有返回一个可读写的mask掩码，则会调用schedule_timeout是调用select的进程（也就是current）进入睡眠。当设备驱动发生自身资源可读写后，会唤醒其等待队列上睡眠的进程。如果超过一定的超时时间（schedule_timeout指定），还是没人唤醒，则调用select的进程会重新被唤醒获得CPU，进而重新遍历fd，判断有没有就绪的fd。
- 把fd_set从内核空间拷贝到用户空间。

###### select的缺点

- 每次调用select，都需要把fd集合从用户太拷贝到内核态
- 每次调用select都需要在内核遍历传递进来的所有fd
- select支持的文件描述符数量太小，1024个

##### poll

​	poll和select实现类型，只有fd集合方式不相同，poll使用pollfd结构而不是select的fd_set结构

##### epoll

​	**epoll提供了三个函数，epoll_create,epool_ctl,epool_wait，第一个是创建epoll句柄，第二个是注册要监听的事件类型，第三个是等待事件的产生。**

- 改进第一个缺点，epoll的解决方案在epoll_ctl汉中中，每次注册新的事件到epoll句柄中，都会把所有的fd拷贝进内核，而不是在epoll_wait的时候重复拷贝，epoll保证了每个fd在这个过程中只会拷贝一次。
- 改进第二个缺点，epoll 的解决方案不像其他函数，每次都把当前轮流加入fd队形的设备的等待队列中，而是只在ctl函数，把current挂一遍并未每个fd指定一个回调函数，当设备就绪，唤醒等待队列中的等待者，就会调用这个回调函数，而这个回调函数会把就绪的fd加入一个就绪列表，wait函数的工作实际就是在这个就绪链表中查看有没有就绪的fd
- 改进第三个缺点，epoll没有这个限制，在1G内存的机器上大约有10万哥左右fd，具体数目可以cat /proc/sys/fs/file-max察看

###### epoll的工作方式

- 边缘触发，仅仅当状态发生变化时才通知，wait函数返回，换句话，就是对于一个事件，只通知一次，且只支持非阻塞
- 电平触发，默认方式。类似于另外两种复用函数，只要还有没有处理的事件就会一直通知，以电平方式调用epoll接口的时候，它相当于一个速度比较快的poll，支持阻塞非阻塞。

##### 总结

- ​	select，poll需要自己不断轮询所有fd集合，知道设备继续，而epoll其实也需要调用wait不断轮询就绪链表，期间也可能多次睡眠和唤醒交替，但是他是设备就绪时，调用回调函数，把就绪的fd放入就绪聊表中，并唤醒在wait中进入睡眠的进程。前两种睡眠时，需要遍历整个fd，而epoll在醒着的时候只要判断一下就绪链表是否为空即可。
- ​	select，poll每次调用都要把fd集合从用户态往内核态拷贝一次，并且要把current往设备等待队列中挂一次，而epoll只要一次拷贝（epoll是通过内核于用户空间mmap同一块内存实现加速内核与用户空间的消息传递），而且把current往等待队列上挂也只挂一次（在epoll_wait的开始，注意这里的等待队列并不是设备等待队列，只是一个epoll内部定义的等待队列），这也能节省不少的开销。



​	

